<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title> - Aphros的个人博客</title><meta name="Description" content="This is my cool site"><meta property="og:title" content="" />
<meta property="og:description" content="基础篇 概述 数据挖掘 (Data Mining) 就是从大量数据中发现隐藏在其中的模式、关联、规律和信息的过程，从数据中提取有价值的知识，并将其转化为可用信息。 机器学习" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/posts/programming/01.%E5%9F%BA%E7%A1%80%E7%AF%87/" /><meta property="article:section" content="posts" />

<meta property="og:site_name" content="Aphros的博客" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="基础篇 概述 数据挖掘 (Data Mining) 就是从大量数据中发现隐藏在其中的模式、关联、规律和信息的过程，从数据中提取有价值的知识，并将其转化为可用信息。 机器学习"/>
<meta name="application-name" content="Aphros的博客">
<meta name="apple-mobile-web-app-title" content="Aphros的博客"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://localhost:1313/posts/programming/01.%E5%9F%BA%E7%A1%80%E7%AF%87/" /><link rel="prev" href="http://localhost:1313/posts/programming/02.%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/" /><link rel="next" href="http://localhost:1313/posts/javascript-tutorial/types/string/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/localhost:1313\/posts\/programming\/01.%E5%9F%BA%E7%A1%80%E7%AF%87\/"
        },"genre": "posts","wordcount":  9378 ,
        "url": "http:\/\/localhost:1313\/posts\/programming\/01.%E5%9F%BA%E7%A1%80%E7%AF%87\/","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "Aphros"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Aphros的个人博客">Aphros的博客</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Aphros的个人博客">Aphros的博客</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX"></h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>Aphros</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="0001-01-01">0001-01-01</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;9378 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;19 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#概述">概述</a></li>
    <li><a href="#数据准备">数据准备</a>
      <ul>
        <li><a href="#数据集成">数据集成</a></li>
        <li><a href="#数据变换">数据变换</a></li>
        <li><a href="#数据归约">数据归约</a></li>
      </ul>
    </li>
    <li><a href="#建立模型">建立模型</a></li>
    <li><a href="#模型评估">模型评估</a>
      <ul>
        <li><a href="#误差与欠拟合过拟合">误差与欠拟合/过拟合</a></li>
        <li><a href="#评估方法">评估方法</a></li>
        <li><a href="#偏差与方差">偏差与方差</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h1 id="基础篇">基础篇</h1>
<h2 id="概述">概述</h2>
<p><strong>数据挖掘 (Data Mining)</strong> 就是从大量数据中发现隐藏在其中的模式、关联、规律和信息的过程，从数据中提取有价值的知识，并将其转化为可用信息。</p>
<p><strong>机器学习（Machine Learning）</strong> 关注如何使计算机系统能够从数据中学习并改进性能，算法会从数据中学习规律，并生成模型，使计算机能够自动做出决策和预测。这种学习过程涉及从数据中提取特征、训练模型、调整参数，以及评估模型的性能。</p>
<ul>
<li>数据挖掘和机器学习的过程：
<ul>
<li><strong>商业理解</strong>确定业务对象、确定数据挖掘目标、制订工程计划</li>
<li><strong>数据理解</strong>收集初始数据、描述数据 、探索数据、验证数据质量</li>
<li><strong>数据准备</strong>特征提取与选择、数据清洗 、数据转换 、数据集成</li>
<li><strong>建立模型</strong>选择建模技术、生成测试设计、构建和评估模型</li>
<li><strong>模型评估</strong>评估结果、查看数据挖掘过程、确定后续步骤</li>
<li><strong>模型部署</strong>计划部署、监视和维护 、生成最终报告、复查</li>
</ul>
</li>
</ul>
<h2 id="数据准备">数据准备</h2>
<ul>
<li>
<p><strong>特征提取</strong>从原始数据中提取有用的特征或属性，以便机器学习模型可以理解和使用。</p>
<ul>
<li>在文本数据中，特征可以是词频、TF-IDF等</li>
<li>在图像数据中，特征可以是像素值、颜色直方图等</li>
</ul>
</li>
<li>
<p><strong>类型转换</strong>将数据的类型进行转换，以便其适合模型的输入要求。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>源数据类型</th>
<th>目标数据类型</th>
<th>方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>数值型</td>
<td>类别型</td>
<td>离散化</td>
</tr>
<tr>
<td>类别型</td>
<td>数值型</td>
<td>二元化</td>
</tr>
<tr>
<td>文本</td>
<td>数值型</td>
<td>潜在语义分析（LSA）</td>
</tr>
<tr>
<td>时序</td>
<td>离散序列</td>
<td>SAX</td>
</tr>
<tr>
<td>时序</td>
<td>多维数值型</td>
<td>DWT、DFT</td>
</tr>
<tr>
<td>离散序列</td>
<td>多维数值型</td>
<td>DWT、DFT</td>
</tr>
<tr>
<td>空间</td>
<td>多维数值型</td>
<td>二维DWT</td>
</tr>
<tr>
<td>图</td>
<td>多维数值型</td>
<td>MDS、图谱</td>
</tr>
<tr>
<td>任何类型</td>
<td>图</td>
<td>相似图（可用性较有限）</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>数据清洗</strong>去除或纠正数据中的错误、缺失、重复或异常值的过程。这可以提高模型的性能和稳定性。清洗数据可以包括填充缺失值、删除重复值、处理异常值等</li>
<li><strong>数据集成</strong>从多个数据源或表中合并数据，以便进行分析和建模。这可能涉及到数据连接、合并和转换，确保数据在合并后的格式中保持一致。</li>
<li><strong>数据变换</strong>将数据进行标准化、归一化或其他变换，以便让不同特征具有相似的尺度，提高模型的性能和收敛速度。</li>
<li><strong>数据归约</strong>通过降维技术来减少数据的维度，以减少存储和计算成本，并防止维度灾难。常见的方法包括主成分分析（PCA）和线性判别分析（LDA）等。</li>
</ul>
<h3 id="数据集成">数据集成</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sqlalchemy</span> <span class="kn">import</span> <span class="n">Column</span><span class="p">,</span> <span class="n">Integer</span><span class="p">,</span> <span class="n">String</span><span class="p">,</span> <span class="n">create_engine</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sqlalchemy.orm</span> <span class="kn">import</span> <span class="n">sessionmaker</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sqlalchemy.ext.declarative</span> <span class="kn">import</span> <span class="n">declarative_base</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 创建 SQLAlchemy Engine，根据不同数据库需要替换对应的连接字符串</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># SQLite 连接示例（使用文件路径）：</span>
</span></span><span class="line"><span class="cl"><span class="c1"># engine = create_engine(&#39;sqlite:///example.db&#39;)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># MySQL 连接示例：</span>
</span></span><span class="line"><span class="cl"><span class="c1"># engine = create_engine(&#39;mysql://username:password@localhost/dbname&#39;)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># PostgreSQL 连接示例：</span>
</span></span><span class="line"><span class="cl"><span class="c1"># engine = create_engine(&#39;postgresql://username:password@localhost/dbname&#39;)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># SQL Server 连接示例：</span>
</span></span><span class="line"><span class="cl"><span class="c1"># engine = create_engine(&#39;mssql+pyodbc://username:password@server/dbname&#39;)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Oracle 连接示例（需要 cx_Oracle 库）：</span>
</span></span><span class="line"><span class="cl"><span class="c1"># engine = create_engine(&#39;oracle+cx_oracle://username:password@hostname:port/service_name&#39;)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 创建 Session 创建函数</span>
</span></span><span class="line"><span class="cl"><span class="n">Session</span> <span class="o">=</span> <span class="n">sessionmaker</span><span class="p">(</span><span class="n">bind</span><span class="o">=</span><span class="n">engine</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 创建 Base 类，用于定义 ORM 映射类</span>
</span></span><span class="line"><span class="cl"><span class="n">Base</span> <span class="o">=</span> <span class="n">declarative_base</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 定义 ORM 映射类</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">User</span><span class="p">(</span><span class="n">Base</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">__tablename__</span> <span class="o">=</span> <span class="s1">&#39;users&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="nb">id</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">Integer</span><span class="p">,</span> <span class="n">primary_key</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">name</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">String</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">age</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">Integer</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用 Base 创建数据表</span>
</span></span><span class="line"><span class="cl"><span class="n">Base</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">create_all</span><span class="p">(</span><span class="n">engine</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用 with 上下文管理器启动会话</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 创建新的用户对象</span>
</span></span><span class="line"><span class="cl">    <span class="n">new_user</span> <span class="o">=</span> <span class="n">User</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Alice&#39;</span><span class="p">,</span> <span class="n">age</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">session</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">new_user</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 在 with 代码块结束时，会话会自动提交或回滚并关闭</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 在这个例子中，会话会自动提交新的用户数据到数据库</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sqlalchemy</span> <span class="kn">import</span> <span class="n">create_engine</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 创建 SQLAlchemy Engine</span>
</span></span><span class="line"><span class="cl"><span class="n">engine</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="s1">&#39;sqlite:///example.db&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用 pandas 的 read_sql() 函数读取数据并创建数据帧</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 在这个示例中，我们从 &#34;users&#34; 表读取数据</span>
</span></span><span class="line"><span class="cl"><span class="n">query</span> <span class="o">=</span> <span class="s2">&#34;SELECT * FROM users1&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">data1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">engine</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">query</span> <span class="o">=</span> <span class="s2">&#34;SELECT * FROM users2&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">data2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">engine</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用 concat() 函数沿着行方向合并数据帧</span>
</span></span><span class="line"><span class="cl"><span class="n">concatenated_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用 merge() 函数基于共同的列 &#39;key&#39; 进行合并</span>
</span></span><span class="line"><span class="cl"><span class="n">merged_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;key&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;inner&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 打印合并后的数据帧</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">concatenated_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">merged_data</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="数据变换">数据变换</h3>
<p><strong>标准化（Standardization）</strong> 标准化也称为Z-score标准化，通过将数据的均值转化为0，标准差转化为1，使数据服从标准正态分布。标准化适用于特征的分布不符合正态分布的情况。</p>
<p><strong>归一化（Normalization）</strong> 归一化将数据范围缩放到 [0, 1] 区间内。这通常是通过对原始值减去最小值并除以范围来实现的。归一化适用于需要确保数据的比例关系不受影响的情况。</p>
<p><strong>Softmax变换（Softmax Transformation）</strong> Softmax变换通常用于多类别分类问题中，将原始分数转换为概率分布。它将分数转换为归一化的概率，以便可以预测每个类别的概率。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">softmax</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 示例数据</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 标准化（Z-score标准化）</span>
</span></span><span class="line"><span class="cl"><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">data_standardized</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 归一化（MinMax缩放）</span>
</span></span><span class="line"><span class="cl"><span class="n">minmax_scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">data_normalized</span> <span class="o">=</span> <span class="n">minmax_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Softmax变换</span>
</span></span><span class="line"><span class="cl"><span class="n">data_softmax</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Original Data:</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Standardized Data:</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">data_standardized</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Normalized Data:</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">data_normalized</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Softmax Transformed Data:</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">data_softmax</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="数据归约">数据归约</h3>
<p><strong>流形学习(manifold learning)</strong> 现实世界中，许多数据集存在于高维空间中，但是这些数据可能分布在比数据维度低得多的流形上。流形学习的目标是将这种复杂的高维数据映射到一个更低维的表示，以便更好地理解数据的内在结构、降低噪声影响以及进行可视化和分析。</p>
<h4 id="常用方法">常用方法</h4>
<ul>
<li><strong>缺失值比率（Missing Value Ratio）</strong>：如果某个特征的缺失值比例很高，可以考虑删除该特征或使用其他方法来填充缺失值。</li>
<li><strong>低方差滤波（Low Variance Filtering）</strong>：用于删除方差很低的特征，这些特征可能携带的信息较少。可以通过计算特征的方差来决定是否保留或删除特征。方差与数据范围相关的，因此在采用该方法前需要对数据做归一化处理。</li>
<li><strong>高相关滤波（High Correlation Filtering）</strong>：用于删除高度相关的特征，以避免多重共线性。当两个特征之间的相关性很高时，可以选择保留其中一个特征。</li>
<li><strong>随机森林（Random Forest）</strong>： 随机森林是一种集成学习方法，可以用于特征选择。通过随机森林中各个决策树的特征重要性评估，可以选择重要的特征。</li>
<li><strong>反向特征消除（Recursive Feature Elimination，RFE）</strong>： 从所有特征开始，反复拟合模型并排除不重要的特征，直到达到所需的特征数量。</li>
<li><strong>前向特征选择（Forward Feature Selection）</strong>： 从空特征集开始，逐步添加对模型性能有贡献的特征，直到达到所需的特征数量或达到最佳性能。</li>
<li><strong>因子分析（Factor Analysis）</strong>： 将变量按其相关性分组，即特定组内所有变量的相关性较高，组间变量的相关性较低。我们把每个组称为一个因子，它是多
个变量的组合。</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">VarianceThreshold</span><span class="p">,</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span><span class="p">,</span><span class="n">mutual_info_classif</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">FactorAnalysis</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载示例数据（鸢尾花数据集）</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># 特征</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>  <span class="c1"># 目标类别</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 低方差滤波</span>
</span></span><span class="line"><span class="cl"><span class="n">variance_selector</span> <span class="o">=</span> <span class="n">VarianceThreshold</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_low_variance</span> <span class="o">=</span> <span class="n">variance_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用F统计量进行高相关滤波</span>
</span></span><span class="line"><span class="cl"><span class="n">num_features_to_select</span> <span class="o">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="n">selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">score_func</span><span class="o">=</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">num_features_to_select</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_selected</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 随机森林特征选择</span>
</span></span><span class="line"><span class="cl"><span class="n">rf_classifier</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rf_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">importances</span> <span class="o">=</span> <span class="n">rf_classifier</span><span class="o">.</span><span class="n">feature_importances_</span>
</span></span><span class="line"><span class="cl"><span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">importances</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">selected_features</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># 选择前两个重要特征</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 反向特征消除</span>
</span></span><span class="line"><span class="cl"><span class="n">rfe_selector</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">rf_classifier</span><span class="p">,</span> <span class="n">n_features_to_select</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_selected</span> <span class="o">=</span> <span class="n">rfe_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用互信息进行前向特征选择</span>
</span></span><span class="line"><span class="cl"><span class="n">num_features_to_select</span> <span class="o">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="n">selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">score_func</span><span class="o">=</span><span class="n">mutual_info_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">num_features_to_select</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_selected</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 因子分析</span>
</span></span><span class="line"><span class="cl"><span class="n">factor_analysis</span> <span class="o">=</span> <span class="n">FactorAnalysis</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_factor</span> <span class="o">=</span> <span class="n">factor_analysis</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="线性降维方法">线性降维方法</h4>
<h5 id="主成分分析pca">主成分分析(PCA)</h5>
<p><strong>主成分分析（Principal Component Analysis，PCA）</strong> 是一种常用的降维技术，用于将高维数据投影到低维空间，以保留尽可能多的数据方差。它通过找到数据中的主要方差方向（主成分），将数据投影到这些主成分上，从而实现降低数据维度的目的。每个主成分都是原始特征的线性组合，且彼此正交。</p>
<ul>
<li>在信号处理领域，我们认为信号具有较大方差，噪声具有较小方差，信号与噪声之比称为信噪比。</li>
<li>信噪比越大意味着数据的质量越好，反之，信噪比越小意味着数据的质量越小。</li>
<li>由此我们不难引出PCA的目标，即最大化投影方差，也就是让数据在主轴上投影的方差最大。</li>
</ul>
<!-- raw HTML omitted -->
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载示例数据（鸢尾花数据集）</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># 特征</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>  <span class="c1"># 目标类别</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 创建PCA对象，指定降维后的维度数量</span>
</span></span><span class="line"><span class="cl"><span class="n">num_components</span> <span class="o">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">num_components</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 执行主成分分析</span>
</span></span><span class="line"><span class="cl"><span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 输出降维后的数据</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Original Data Shape:&#34;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;PCA Transformed Data Shape:&#34;</span><span class="p">,</span> <span class="n">X_pca</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span></code></pre></div><h5 id="线性判别分析lda">线性判别分析(LDA)</h5>
<p><strong>线性判别分析（Linear Discriminant Analysis，LDA）</strong> 是一种用于分类和降维的统计方法，用于在多类别问题中找到最佳的投影方向，以便在新空间中实现类别的最大可分性。与主成分分析（PCA）不同，LDA是有监督的方法，它考虑了类别信息来优化投影方向。</p>
<ul>
<li>
<p>LDA的目标是将不同类别的样本在新的低维空间中最大程度地分开，同时尽量将同一类别的样本投影到靠近一起的位置。</p>
</li>
<li>
<p>它通过计算类间散布矩阵（类别之间的差异）和类内散布矩阵（类别内的差异）来选择最佳的投影方向。</p>
</li>
<li>
<p>最终，LDA会选择投影方向，使得类间散布矩阵与类内散布矩阵的比值最大化。</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-PYTHON" data-lang="PYTHON"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="kn">import</span> <span class="n">LinearDiscriminantAnalysis</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载示例数据（鸢尾花数据集）</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># 特征</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>  <span class="c1"># 目标类别</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 创建LDA对象，指定降维后的维度数量</span>
</span></span><span class="line"><span class="cl"><span class="n">num_components</span> <span class="o">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="n">lda</span> <span class="o">=</span> <span class="n">LinearDiscriminantAnalysis</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">num_components</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 执行线性判别分析</span>
</span></span><span class="line"><span class="cl"><span class="n">X_lda</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 输出降维后的数据</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Original Data Shape:&#34;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;LDA Transformed Data Shape:&#34;</span><span class="p">,</span> <span class="n">X_lda</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span></code></pre></div><h5 id="pca-vs-lda">PCA vs. LDA</h5>
<ul>
<li>
<p>相同点</p>
<ul>
<li>两者均可以对数据进行降维。</li>
<li>两者在降维时均使用了矩阵特征分解的思想。</li>
<li>两者都假设数据符合高斯分布。</li>
</ul>
</li>
<li>
<p>不同点</p>
<ul>
<li>LDA是有监督的降维方法，而PCA是无监督的降维方法。</li>
<li>LDA降维最多降到类别数 k-1 的维数，而PCA没有这个限制。</li>
<li>LDA除了可以用于降维，还可以用于分类。</li>
<li>LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。</li>
</ul>
</li>
</ul>
<h5 id="独立分量分析ica">独立分量分析(ICA)</h5>
<p><strong>独立分量分析（Independent Component Analysis，ICA）</strong> 是一种用于盲源分离的统计方法，用于从混合信号中恢复原始信号，前提是这些信号是相互独立的。ICA 假设混合信号是通过线性组合和一定的非线性变换得到的，目标是通过找到一组分离独立信号的线性组合来还原原始信号。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-PYTHON" data-lang="PYTHON"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">FastICA</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载示例数据（鸢尾花数据集）</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># 特征</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>  <span class="c1"># 目标类别</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用FastICA进行独立分量分析</span>
</span></span><span class="line"><span class="cl"><span class="n">ica</span> <span class="o">=</span> <span class="n">FastICA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">S_pred</span> <span class="o">=</span> <span class="n">ica</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 输出分离的独立信号</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Original Signals:</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Mixed Signals:</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Separated Signals:</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">S_pred</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="非线性降维方法">非线性降维方法</h4>
<h5 id="核主成分分析kernel-pca">核主成分分析(Kernel PCA)</h5>
<p>**核主成分分析（Kernel Principal Component Analysis，Kernel PCA）**是主成分分析（PCA）的一种扩展形式，用于在非线性数据上进行降维。与传统的PCA不同，Kernel PCA通过应用核函数来处理非线性关系，从而在高维特征空间中找到最佳的投影方向。核PCA的步骤与传统PCA类似，但在计算协方差矩阵时，它使用了核函数来实现非线性变换。这使得核PCA能够在保留非线性特征的同时，实现数据的降维。</p>
<p><strong>计算步骤</strong>：</p>
<ul>
<li>中心化数据：同样将每个特征值减去对应特征的均值，以确保数据的中心位于原点。</li>
<li>计算核矩阵：使用选择的核函数（如径向基函数核 &lsquo;rbf&rsquo;）计算核矩阵，核矩阵的每个元素表示两个样本之间的核函数值。</li>
<li>计算中心化核矩阵：对核矩阵进行中心化处理，确保中心位于原点。</li>
<li>特征值分解：对中心化核矩阵进行特征值分解，得到特征值和特征向量。</li>
<li>选择主成分：根据特征值的大小，选择要保留的主成分数量。</li>
</ul>
<p><strong>核函数</strong>：</p>
<ul>
<li><strong>线性核（Linear Kernel）</strong>：
<ul>
<li>适用范围：适用于线性可分的数据。</li>
<li>公式：$K(x, y) = x^T y$</li>
</ul>
</li>
<li><strong>多项式核（Polynomial Kernel）</strong>：
<ul>
<li>适用范围：适用于数据具有多项式关系的情况。</li>
<li>公式：$K(x, y) = (x^T y + c)^d$</li>
</ul>
</li>
<li><strong>径向基函数核（RBF Kernel）</strong>：
<ul>
<li>适用范围：适用于各种非线性关系，常用于核PCA中。</li>
<li>公式：$K(x, y) = \exp(-\gamma |x - y|^2)$</li>
</ul>
</li>
<li><strong>Sigmoid核</strong>：
<ul>
<li>适用范围：适用于捕捉数据间的非线性关系，但在某些情况下可能不如其他核函数效果好。</li>
<li>公式：$K(x, y) = \tanh(\alpha x^T y + c)$</li>
</ul>
</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-PYTHON" data-lang="PYTHON"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">KernelPCA</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_circles</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 生成非线性数据（环形数据）</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_circles</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用KernelPCA进行降维</span>
</span></span><span class="line"><span class="cl"><span class="n">kernel_pca</span> <span class="o">=</span> <span class="n">KernelPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_kpca</span> <span class="o">=</span> <span class="n">kernel_pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 输出降维后的数据</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Original Data Shape:&#34;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;KernelPCA Transformed Data Shape:&#34;</span><span class="p">,</span> <span class="n">X_kpca</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span></code></pre></div><h5 id="多维缩放mds">多维缩放（MDS）</h5>
<p>**多维缩放（Multidimensional Scaling，MDS）**是一种用于在低维空间中可视化高维数据的技术。它通过保持数据点之间的距离关系来将数据点映射到一个更低维度的空间，以便于可视化和分析。</p>
<ul>
<li><strong>度量MDS</strong> 度量MDS试图在低维空间中保持数据点之间的欧氏距离或其他距离度量。它通过优化过程来调整低维空间中的点的位置，使得它们之间的距离与原始高维空间中的距离尽量接近。</li>
<li><strong>非度量MDS</strong>： 非度量MDS关注于保持数据点之间的顺序关系，而不一定保持精确的距离。它通过定义一种映射函数，将原始高维空间中的排序关系映射到低维空间中，使得排列顺序尽量保持一致。</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">MDS</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载示例数据（手写数字数据集）</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># 特征</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>  <span class="c1"># 目标类别</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用MDS进行降维</span>
</span></span><span class="line"><span class="cl"><span class="n">mds</span> <span class="o">=</span> <span class="n">MDS</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_mds</span> <span class="o">=</span> <span class="n">mds</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 输出降维后的数据</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Original Data Shape:&#34;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;MDS Transformed Data Shape:&#34;</span><span class="p">,</span> <span class="n">X_mds</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span></code></pre></div><h5 id="等度量映射isomap">等度量映射（ISOMAP）</h5>
<p>**等度量映射（Isometric Feature Mapping，ISOMAP）**是一种用于非线性降维的技术，旨在在保持数据点之间的测地距离关系的同时将数据映射到一个更低维度的空间。ISOMAP基于流形学习的思想，可以在高维数据中发现潜在的流形结构，并在降维后保持这种结构。</p>
<p>ISOMAP主要用于处理高维数据中的非线性关系，特别适用于捕捉数据中的流形结构，如螺旋、环形等。它基于数据点之间的测地距离（沿流形表面的最短路径距离），而不是简单的欧氏距离</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">Isomap</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载示例数据（手写数字数据集）</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># 特征</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>  <span class="c1"># 目标类别</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用ISOMAP进行降维</span>
</span></span><span class="line"><span class="cl"><span class="n">isomap</span> <span class="o">=</span> <span class="n">Isomap</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_isomap</span> <span class="o">=</span> <span class="n">isomap</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 输出降维后的数据</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Original Data Shape:&#34;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;ISOMAP Transformed Data Shape:&#34;</span><span class="p">,</span> <span class="n">X_mds</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span></code></pre></div><h5 id="局部线性嵌入lle">局部线性嵌入（LLE）</h5>
<p>**局部线性嵌入（Locally Linear Embedding，LLE）**是一种用于非线性降维的流形学习方法，旨在保持数据点之间的局部线性关系。LLE通过分析每个数据点与其最近邻数据点之间的线性关系，将数据映射到一个更低维度的空间，从而捕捉数据的流形结构。</p>
<p>LLE的核心思想是，将每个数据点表示为其最近邻数据点的线性组合，然后在低维空间中找到能够保持这些线性组合关系的映射。LLE分为三个主要步骤：局部权重计算、重建权重计算和全局映射。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">LocallyLinearEmbedding</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载示例数据（手写数字数据集）</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># 特征</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>  <span class="c1"># 目标类别</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用LLE进行降维</span>
</span></span><span class="line"><span class="cl"><span class="n">lle</span> <span class="o">=</span> <span class="n">LocallyLinearEmbedding</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_lle</span> <span class="o">=</span> <span class="n">lle</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 输出降维后的数据</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Original Data Shape:&#34;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;LLE Transformed Data Shape:&#34;</span><span class="p">,</span> <span class="n">X_mds</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span></code></pre></div><h5 id="t-分布随机近邻嵌入t-sne">t-分布随机近邻嵌入(t-SNE)</h5>
<p>**t-分布随机近邻嵌入（t-distributed stochastic neighbor embedding, t-SNE）**是一种用于降维和数据可视化的非线性方法，旨在将高维数据映射到一个低维空间，以便于观察数据的类别和相似性结构。t-SNE特别适用于在降维后保留数据之间的局部相似性关系。</p>
<p>t-SNE通过构建一个概率分布来捕捉高维空间中数据点之间的相似性，然后在低维空间中构建一个类似的概率分布，以最小化这两个概率分布之间的Kullback-Leibler散度。该方法强调在低维空间中保持邻近数据点之间的相似性，并尽量将不同类别的数据点分开。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载示例数据（手写数字数据集）</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># 特征</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>  <span class="c1"># 目标类别</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用t-SNE进行降维</span>
</span></span><span class="line"><span class="cl"><span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_tsne</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 输出降维后的数据</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Original Data Shape:&#34;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;t-SNE Transformed Data Shape:&#34;</span><span class="p">,</span> <span class="n">X_mds</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="建立模型">建立模型</h2>
<ul>
<li><strong>监督学习（Supervised Learning）</strong>：使用有标签的训练数据来学习输入和输出之间的映射关系，以便进行预测。
<ul>
<li>分类（Classisification）：标签是离散值</li>
<li>回归（Regression）：标签是连续值</li>
</ul>
</li>
<li><strong>无监督学习（Unsupervised Learning）</strong>：处理没有标签的数据，试图发现数据中的模式和结构。
<ul>
<li>聚类（Clustering）</li>
<li>异常检测和新颖性检测</li>
<li>可视化和降维</li>
<li>关联性规则学习</li>
</ul>
</li>
<li><strong>半监督学习（Semi-Supervised Learning）</strong>：结合了监督和无监督学习，通常使用大量不带标签数据加上小部分带标签数据进行训练。
<ul>
<li>深度信念网络（DBN）是基于被称为互相叠加的受限玻尔兹曼机（RBM）的非监督组件。RBM 是先用非监督方法进行训练，再用监督学习方法进行整个系统微调。</li>
</ul>
</li>
</ul>
<!-- raw HTML omitted -->
<ul>
<li><strong>强化学习（Reinforcement Learning）</strong>：算法学习在与环境的交互中，通过采取行动来最大化累积奖励。</li>
</ul>
<!-- raw HTML omitted -->
<ul>
<li><strong>迁移学习（Transfer Learning）</strong>：迁移学习利用在一个任务上学到的知识，来改进在另一个相关任务上的性能。</li>
<li><strong>深度学习（Deep Learning）</strong>：深度学习是一种特殊的机器学习方法，使用深层神经网络来建模和学习复杂的模式和特征。</li>
</ul>
<h2 id="模型评估">模型评估</h2>
<h3 id="误差与欠拟合过拟合">误差与欠拟合/过拟合</h3>
<p>**误差（error）**模型的预测值与实际观测值之间的差异</p>
<ul>
<li>训练误差（training error）或经验误差（empirical error）：模型在训练数据上的误差</li>
<li>测试误差（test error）：模型在测试数据上的误差</li>
<li>泛化误差（generalization error）：模型在训练数据、测试数据以及其他未知数据上的预测误差</li>
</ul>
<p>**欠拟合（Underfitting）**模型的复杂度不足，不能很好地拟合数据的细节，训练误差和测试误差通常都较高</p>
<p>**过拟合（Overfitting）**模型过于复杂，对训练数据中的噪音和细节过于敏感，在训练数据上表现优秀，但在未见过的新数据上表现不佳。</p>
<h3 id="评估方法">评估方法</h3>
<p>无法直接获得<strong>泛化误差</strong>，使用<strong>测试误差</strong>来作为<strong>泛化误差</strong>的近似</p>
<h4 id="划分方法">划分方法</h4>
<ul>
<li>
<p>**留出法（Holdout Method）**将数据集按照一定比例划分为训练集和测试集两部分，训练集用于训练模型，测试集用于评估模型的性能。留出法简单实用，但在数据较少时可能不够准确，容易因数据分布的随机性而导致评估结果不稳定。</p>
</li>
<li>
<p>**交叉验证法（Cross-Validation）**将数据划分为多个子集，轮流将其中一个子集作为测试集，其他子集作为训练集，进行多次训练和测试，以获得更稳定的评估结果。交叉验证可以更准确地估计模型的性能，特别是在数据较少或不平衡的情况下。</p>
</li>
<li>
<p>**自助法（Bootstrap Method）**通过从原始数据集中有放回地抽样，构建多个大小相同的训练集，并使用未被选中的样本作为测试集。自助法适用于数据较少的情况下，能够利用重复抽样生成多个数据集来进行评估。</p>
</li>
</ul>
<h4 id="性能度量">性能度量</h4>
<p><strong>性能度量（performance measure）<strong>是衡量模型</strong>泛化能力</strong>的评价标准，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果。</p>
<h5 id="分类问题">分类问题</h5>
<ul>
<li><strong>混淆矩阵</strong></li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>预测为正类</th>
<th>预测为负类</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>实际为正类</strong></td>
<td>TP</td>
<td>FN</td>
</tr>
<tr>
<td><strong>实际为负类</strong></td>
<td>FP</td>
<td>TN</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&#34;d&#34;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&#34;Blues&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><ul>
<li>**错误率（Error Rate）**模型预测错误的样本数占总样本数的比例，表示模型预测错误的整体程度。</li>
</ul>
<p>$$
Error Rate = \frac{FP + FN}{TP + TN + FP + FN}
$$</p>
<ul>
<li>**精度（Accuracy）**模型正确预测的样本数占总样本数的比例，表示模型的整体预测准确率。</li>
</ul>
<p>$$
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
$$</p>
<ul>
<li>**查准率(Precision)**在模型预测为正类的情况下，实际为正类的比例，关注于预测为正类的样本中有多少是真正的正类。</li>
</ul>
<p>$$
Precision = \frac{TP}{TP + FP}
$$</p>
<ul>
<li>**查全率（Recall）**在实际为正类的情况下，模型预测为正类的比例，关注于模型是否能够捕获到所有真正的正类。</li>
</ul>
<p>$$
Recall = \frac{TP}{TP + FN}
$$</p>
<ul>
<li><strong>F1 分数（F1-Score）<strong>查准率和查全率的</strong>调和平均</strong>，用于综合考虑模型的准确性和覆盖率，适用于不平衡数据集，能够平衡查准率和查全率之间的权衡。</li>
</ul>
<p>$$
F1\text{-}Score = \frac{2 \times Precision \times Recall}{Precision + Recall}
$$</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 真实标签和预测标签</span>
</span></span><span class="line"><span class="cl"><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 计算精度</span>
</span></span><span class="line"><span class="cl"><span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Accuracy:&#34;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 计算错误率</span>
</span></span><span class="line"><span class="cl"><span class="n">error_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">accuracy</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Error rate:&#34;</span><span class="p">,</span> <span class="n">error_rate</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 计算查准率</span>
</span></span><span class="line"><span class="cl"><span class="n">precision</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Precision:&#34;</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 计算查全率</span>
</span></span><span class="line"><span class="cl"><span class="n">recall</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Recall:&#34;</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 计算F1分数</span>
</span></span><span class="line"><span class="cl"><span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;F1 score:&#34;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
</span></span></code></pre></div><ul>
<li><strong>P-R 曲线</strong>以模型的查准率（Precision）为纵轴，查全率（Recall）为横轴，绘制的曲线，表示在<strong>不同阈值</strong>下模型的表现，以及在查准率和查全率之间的权衡。</li>
</ul>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="http://192.168.0.103:7788/images/2023/08/24/image-20230824125603800.png"
        data-srcset="http://192.168.0.103:7788/images/2023/08/24/image-20230824125603800.png, http://192.168.0.103:7788/images/2023/08/24/image-20230824125603800.png 1.5x, http://192.168.0.103:7788/images/2023/08/24/image-20230824125603800.png 2x"
        data-sizes="auto"
        alt="http://192.168.0.103:7788/images/2023/08/24/image-20230824125603800.png"
        title="image-20230824125603800" /></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">plot_pr_curve</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;PR curve&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Recall&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Precision&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Precision-Recall Curve&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 计算PR曲线</span>
</span></span><span class="line"><span class="cl"><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plot_pr_curve</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
</span></span></code></pre></div><ul>
<li><strong>ROC 曲线</strong>以模型的真正类率（也称为查全率）为纵轴，假正类率（实际为负预测为正）为横轴，绘制的曲线，表示在<strong>不同阈值</strong>下模型的表现，以及在查全率和假正类率之间的权衡。</li>
</ul>
<!-- raw HTML omitted -->
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">plot_roc_curve</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">auc_value</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;ROC curve (AUC = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">auc_value</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Random&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Area under curve&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate (FPR)&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate (TPR)&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Receiver Operating Characteristic (ROC) Curve&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 计算ROC曲线</span>
</span></span><span class="line"><span class="cl"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">auc_value</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plot_roc_curve</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">auc_value</span><span class="p">)</span>
</span></span></code></pre></div><ul>
<li><strong>AUC 值</strong>ROC曲线下的面积，范围在0到1之间，表示了模型能够正确分类正类和负类的能力，越接近1表示模型性能越好，可以理解为在随机选择一个正类样本和一个负类样本的情况下，模型预测正类的概率高于预测负类的概率的概率。</li>
<li><strong>代价矩阵（Cost Matrix）</strong></li>
</ul>
<p>$$
\begin{bmatrix}
C_{TP} &amp; C_{FN} \
C_{FP} &amp; C_{TN}
\end{bmatrix}
$$</p>
<ul>
<li>**代价敏感错误率（Cost-Sensitive Error Rate）**考虑了不同类别预测错误所带来的代价而计算得出的错误率。</li>
</ul>
<p>$$
Cost\text{-}Sensitive\ Error\ Rate = \frac{C_{FP} \cdot FN + C_{FN} \cdot FP}{C_{TP} \cdot (FP + TN) + C_{FN} \cdot (TP + FN)}
$$</p>
<ul>
<li>**代价曲线（Cost Curve）**是根据不同阈值下的代价矩阵计算得出的曲线。在代价曲线中，横轴表示不同的阈值，纵轴表示在不同阈值下的总代价或平均代价。代价曲线可以帮助决策者在代价和效益之间进行权衡，选择适当的模型阈值。</li>
</ul>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="http://192.168.0.103:7788/images/2023/08/24/image-20230824133154197.png"
        data-srcset="http://192.168.0.103:7788/images/2023/08/24/image-20230824133154197.png, http://192.168.0.103:7788/images/2023/08/24/image-20230824133154197.png 1.5x, http://192.168.0.103:7788/images/2023/08/24/image-20230824133154197.png 2x"
        data-sizes="auto"
        alt="http://192.168.0.103:7788/images/2023/08/24/image-20230824133154197.png"
        title="image-20230824133154197" /></p>
<h5 id="回归问题">回归问题</h5>
<ul>
<li><strong>均方误差</strong></li>
</ul>
<p>$$
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 真实值和预测值</span>
</span></span><span class="line"><span class="cl"><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 计算均方误差</span>
</span></span><span class="line"><span class="cl"><span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Mean Squared Error:&#34;</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="比较检验">比较检验</h4>
<p><strong>比较检验</strong>根据数据集以及模型任务的特征，选出最合适的性能度量方法，对单个或多个学习器在不同或相同测试集上的性能度量结果做比较</p>
<h5 id="单个学习器泛化进行检验">单个学习器泛化进行检验</h5>
<p><strong>二项检验（Binomial Test）</strong> 一个二分类模型，检验它的性能是否显著优于随机猜测，需要知道测试集中的正样本比例（成功概率）以及模型预测的正类数量。二项检验会给出一个p值，表示在随机猜测情况下，获得至少和模型一样好的结果的概率。如果p值很小（通常小于0.05），那么模型在测试数据上的性能是显著的。</p>
<p><strong>t检验（t-test）</strong>： 用于比较两个平均值是否显著不同，适用于回归问题的情况。将模型的预测值与实际标签之间的误差作为数据，然后使用t检验来判断模型的性能是否显著优于随机猜测。与二项检验不同，t检验更关注误差的大小和分布。如果t检验得出的p值较小，那么模型的预测误差与随机猜测之间的差异是显著的。
$$
\tau_t=|\frac{\sqrt{k}(\mu-\epsilon_0)}{\sigma}|
$$</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 示例数据</span>
</span></span><span class="line"><span class="cl"><span class="n">model_scores</span> <span class="o">=</span> <span class="p">[</span><span class="mi">85</span><span class="p">,</span> <span class="mi">89</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">78</span><span class="p">,</span> <span class="mi">88</span><span class="p">,</span> <span class="mi">82</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="mi">91</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 假设均值为期望值（例如50）</span>
</span></span><span class="line"><span class="cl"><span class="n">expected_mean</span> <span class="o">=</span> <span class="mi">50</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 执行t检验</span>
</span></span><span class="line"><span class="cl"><span class="n">t_statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_1samp</span><span class="p">(</span><span class="n">model_scores</span><span class="p">,</span> <span class="n">expected_mean</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Reject null hypothesis: The mean is significantly different.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Fail to reject null hypothesis: No significant difference in the mean.&#34;</span><span class="p">)</span>
</span></span></code></pre></div><h5 id="不同学习器泛化进行检验">不同学习器泛化进行检验</h5>
<p><strong>交叉验证t检验</strong>比较不同学习器在同一数据集上的性能的方法。首先，对每个学习器进行交叉验证，得到各自的性能指标（如精度、F1分数等）。然后，可以使用t检验来判断不同学习器的性能是否存在显著差异。
$$
\tau_t=|\frac{\sqrt{k}\mu}{\sigma}|
$$</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">t_statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_rel</span><span class="p">(</span><span class="n">model1_scores</span><span class="p">,</span> <span class="n">model2_scores</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Models have significantly different performance.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;No significant difference between models.&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p><strong>McNemar检验</strong>： 关注模型在分类结果上的显著差异，以确定是否有一个模型在某些情况下比另一个模型表现更好，使用$\chi^2$检验来判断不同学习器的性能是否存在显著差异。</p>
<table>
<thead>
<tr>
<th></th>
<th>模型 2 正确</th>
<th>模型 2 错误</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Model 1 正确</strong></td>
<td>$e_{00}$</td>
<td>$e_{01}$</td>
</tr>
<tr>
<td><strong>Model 1 错误</strong></td>
<td>$e_{10}$</td>
<td>$e_{11}$</td>
</tr>
</tbody>
</table>
<p>$$
\tau_{\chi^2} = \frac{(|e_{01} - e_{10}| - 1)^2}{(e_{01} + e_{10})}
$$</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">statsmodels.stats.contingency_tables</span> <span class="kn">import</span> <span class="n">mcnemar</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 构建混淆矩阵</span>
</span></span><span class="line"><span class="cl"><span class="n">confusion_matrix</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">60</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 执行McNemar检验</span>
</span></span><span class="line"><span class="cl"><span class="n">result</span> <span class="o">=</span> <span class="n">mcnemar</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">exact</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">pvalue</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Reject null hypothesis: There is a significant difference.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Fail to reject null hypothesis: No significant difference.&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p><strong>Friedman检验与Nemenyi后续检验</strong>： 多个不同学习器在多个数据集上进行比较，Friedman检验可以用来检验学习器之间的整体差异。如果Friedman检验得出显著结果，可以使用Nemenyi后续检验来确定哪些学习器之间存在显著差异。</p>
<p><strong>Friedman检验</strong>：</p>
<ul>
<li>对每个学习器在每个数据集上的性能进行排名。</li>
<li>计算每个学习器的平均排名。</li>
<li>计算每个学习器的平均排名秩。</li>
<li>使用计算得出的统计量进行Friedman检验，得到一个p值。</li>
<li>如果p值小于显著性水平（通常为0.05），则可以拒绝假设，认为至少有一个学习器在不同数据集上的性能存在显著差异。</li>
</ul>
<p><strong>Nemenyi后续检验</strong>：</p>
<ul>
<li>计算学习器之间的平均排名差。</li>
<li>根据学习器的数量和数据集数量，确定显著性水平下的临界值。</li>
<li>比较平均排名差是否超过临界值，从而确定学习器之间的显著性差异。</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">friedmanchisquare</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scikit_posthocs</span> <span class="kn">import</span> <span class="n">posthoc_nemenyi</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 示例数据</span>
</span></span><span class="line"><span class="cl"><span class="n">model1_scores</span> <span class="o">=</span> <span class="p">[</span><span class="mi">85</span><span class="p">,</span> <span class="mi">89</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">78</span><span class="p">,</span> <span class="mi">88</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">model2_scores</span> <span class="o">=</span> <span class="p">[</span><span class="mi">75</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">92</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">85</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">model3_scores</span> <span class="o">=</span> <span class="p">[</span><span class="mi">95</span><span class="p">,</span> <span class="mi">88</span><span class="p">,</span> <span class="mi">91</span><span class="p">,</span> <span class="mi">85</span><span class="p">,</span> <span class="mi">90</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 执行Friedman检验</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">model1_scores</span><span class="p">,</span> <span class="n">model2_scores</span><span class="p">,</span> <span class="n">model3_scores</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
</span></span><span class="line"><span class="cl"><span class="n">friedman_result</span> <span class="o">=</span> <span class="n">friedmanchisquare</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">friedman_result</span><span class="o">.</span><span class="n">pvalue</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Reject null hypothesis: There is a significant difference.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># 执行Nemenyi后续检验</span>
</span></span><span class="line"><span class="cl">    <span class="n">nemenyi_result</span> <span class="o">=</span> <span class="n">posthoc_nemenyi</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">nemenyi_result</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Fail to reject null hypothesis: No significant difference.&#34;</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="偏差与方差">偏差与方差</h3>
<p><strong>偏差</strong>：描述模型的预测值与真实值之间的差异，高偏差意味着模型过于简单，不能很好地拟合数据，导致欠拟合。</p>
<p><strong>方差</strong>：描述模型在不同训练集上的预测值的变化，用来衡量模型对训练集的敏感程度。高方差意味着模型过于复杂，对训练数据过度拟合，但在新数据上可能表现不佳，导致过拟合。</p>
<!-- raw HTML omitted -->
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 0001-01-01</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="http://localhost:1313/posts/programming/01.%E5%9F%BA%E7%A1%80%E7%AF%87/" data-title=""><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="http://localhost:1313/posts/programming/01.%E5%9F%BA%E7%A1%80%E7%AF%87/"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="http://localhost:1313/posts/programming/01.%E5%9F%BA%E7%A1%80%E7%AF%87/" data-title=""><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="http://localhost:1313/posts/programming/01.%E5%9F%BA%E7%A1%80%E7%AF%87/" data-title=""><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="http://localhost:1313/posts/programming/01.%E5%9F%BA%E7%A1%80%E7%AF%87/" data-title=""><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/programming/02.%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/" class="prev" rel="prev" title=""><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i></a>
            <a href="/posts/javascript-tutorial/types/string/" class="next" rel="next" title=""><i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.118.2">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden="true"></i> LoveIt</a>
                </div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2022 - 2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">Aphros</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/copy-tex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
